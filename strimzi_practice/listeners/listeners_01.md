# Strimzi Kafka Operator listeners

Strimzi Kafka Operator 目前支持三种监听方法，分别是：

1. Plain listener on port 9092 (without TLS encryption)
2. TLS listener on port 9093 (with TLS encryption)
3. External listener on port 9094 for access from outside of Kubernetes

对于每一种监听方法又分别有不同的认证方式：

1. Plain listener on port 9092 (without TLS encryption) 只支持 SCRAM-SHA authentication
2. TLS listener on port 9093 (with TLS encryption) 支持两种认证方式，分别是：
   - SCRAM-SHA authentication.
   - Mutual TLS authentication
3. External listener on port 9094 for access from outside of Kubernetes，External listener 有多种不同的类型，不同的类型又分别支持不同的认证方式，后续具体说明。

对于授权方式，两点说明如下：

1. 只有配置了认证方式授权方式才可能生效。
2. 目前只有一种授权方式，Simple authorization

所以，验证 Strimzi Kafka Operator 的三种监听过程的组合如下：

| 编号  | listeners                  | authentication | authorization |
| --- | -------------------------- | -------------- | ------------- |
| 1   | plain                      | scram-sha-512  | simple        |
| 2   | tls                        | scram-sha-512  | simple        |
| 3   | tls                        | tls            | simple        |
| 4   | external(nodeport) - plain | scram-sha-512  | simple        |
| 5   | external(nodeport) - tls   | scram-sha-512  | simple        |
| 6   | external(nodeport) - tls   | tls            | simple        |

## 默认

```yaml
apiVersion: kafka.strimzi.io/v1beta1
kind: Kafka
metadata:
  name: my-cluster
  namespace: kafka
spec:
  entityOperator:
    topicOperator: {}
    userOperator: {}
  kafka:
    config:
      log.message.format.version: '2.5'
      offsets.topic.replication.factor: 3
      transaction.state.log.min.isr: 2
      transaction.state.log.replication.factor: 3
    jmxOptions:
      '-Xms': 8192m
      '-Xmx': 8192m
    listeners:
      plain: {}
      tls: {}
    replicas: 3
    resources:
      limits:
        cpu: '1'
        memory: 1Gi
      requests:
        cpu: 500m
        memory: 500Mi
    storage:
      type: ephemeral
    version: 2.5.0
  zookeeper:
    jmxOptions:
      '-Xms': 4096m
      '-Xmx': 4096m
    replicas: 3
    resources:
      limits:
        cpu: '1'
        memory: 1000Mi
      requests:
        cpu: 500m
        memory: 500Mi
    storage:
      type: ephemeral

##############################
##############################
# This file is automatically generated by the Strimzi Cluster Operator
# Any changes to this file will be ignored and overwritten!
##############################
##############################

##########
# Broker ID
##########
broker.id=0

##########
# Zookeeper
##########
zookeeper.connect=localhost:2181

##########
# Kafka message logs configuration
##########
log.dirs=/var/lib/kafka/data/kafka-log0

##########
# Replication listener
##########

# ssl.keystore.location
# 密钥存储文件的位置。 这对于客户端是可选的，可用于客户端的双向身份验证。

# ssl.keystore.password
# The store password for the key store file. This is optional for client and only needed if ssl.keystore.location is configured.

# ssl.keystore.type
# The file format of the key store file. This is optional for client.

# ssl.truststore.location
# The location of the trust store file.

# ssl.truststore.password
# The password for the trust store file. If a password is not set access to the truststore is still available, but integrity checking is disabled.

# ssl.truststore.type
# The file format of the trust store file.

# ssl.client.auth
# 配置 kafka 代理以请求客户端身份验证。 以下设置是常见的：
# ssl.client.auth=required 如果设置为 required 则需要客户端身份验证。
# ssl.client.auth=requested 这意味着客户端身份验证是可选的。不像 required 的那样，如果设置了这个选项，客户端可以选择不提供关于它自己的认证信息。
# ssl.client.auth=none 这意味着不需要客户端身份验证。

# cluster-ca-certs                         ->  /tmp/kafka/cluster.truststore.p12
# broker-certs                             ->  /tmp/kafka/cluster.keystore.p12
# certificates/custom-tls-9093-certs       ->  /tmp/kafka/custom-tls-9093.keystore.p12
# certificates/custom-external-9094-certs  ->  /tmp/kafka/custom-external-9094.keystore.p12
# client-ca-certs                          ->  /tmp/kafka/clients.truststore.p12
# certificates/oauth-plain-9092-certs      ->  /tmp/kafka/oauth-plain-9092.truststore.p12
# certificates/oauth-tls-9093-certs        ->  /tmp/kafka/oauth-tls-9093.truststore.p12
# certificates/oauth-external-9094-certs   ->  /tmp/kafka/oauth-external-9094.truststore.p12
# certificates/authz-keycloak-certs        ->  /tmp/kafka/authz-keycloak.truststore.p12

listener.name.replication-9091.ssl.keystore.location=/tmp/kafka/cluster.keystore.p12
listener.name.replication-9091.ssl.keystore.password=JaysaGKgZrdJWNiVHFcFJhIQdyKcKl9x
listener.name.replication-9091.ssl.keystore.type=PKCS12
listener.name.replication-9091.ssl.truststore.location=/tmp/kafka/cluster.truststore.p12
listener.name.replication-9091.ssl.truststore.password=JaysaGKgZrdJWNiVHFcFJhIQdyKcKl9x
listener.name.replication-9091.ssl.truststore.type=PKCS12
listener.name.replication-9091.ssl.client.auth=required

##########
# Plain listener
##########

##########
# TLS listener
##########
listener.name.tls-9093.ssl.keystore.location=/tmp/kafka/cluster.keystore.p12
listener.name.tls-9093.ssl.keystore.password=JaysaGKgZrdJWNiVHFcFJhIQdyKcKl9x
listener.name.tls-9093.ssl.keystore.type=PKCS12

##########
# Common listener configuration
##########
# 侦听器列表 - 我们将侦听的 URI 的逗号分隔列表和侦听器名称。
# 如果侦听器名称不是安全协议，还必须设置 listener.security.protocol.map。
listeners=
REPLICATION-9091://0.0.0.0:9091,
PLAIN-9092://0.0.0.0:9092,
TLS-9093://0.0.0.0:9093

advertised.listeners=
REPLICATION-9091://my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc:9091,
PLAIN-9092://my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc:9092,
TLS-9093://my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc:9093

listener.security.protocol.map=REPLICATION-9091:SSL,PLAIN-9092:PLAINTEXT,TLS-9093:SSL

inter.broker.listener.name=REPLICATION-9091

# sasl.enabled.mechanisms
# Kafka 服务器中启用的 SASL 机制列表。 该列表可能包含安全提供程序可用的任何机制。 默认情况下仅启用 GSSAPI。
sasl.enabled.mechanisms=

# ssl.secure.random.implementation
# 用于 SSL 加密操作的 SecureRandom PRNG 实现。
ssl.secure.random.implementation=SHA1PRNG

# ssl.endpoint.identification.algorithm
# 使用服务器证书验证服务器主机名的端点识别算法。
ssl.endpoint.identification.algorithm=HTTPS

##########
# User provided configuration
##########
log.message.format.version=2.5
offsets.topic.replication.factor=3
transaction.state.log.min.isr=2
transaction.state.log.replication.factor=3


############################################################################################


apiVersion: kafka.strimzi.io/v1beta1
kind: Kafka
metadata:
  name: my-cluster
  namespace: hz-kafka
spec:
  entityOperator:
    topicOperator: {}
    userOperator: {}
  kafka:
    config:
      log.message.format.version: '2.5'
      offsets.topic.replication.factor: 3
      transaction.state.log.min.isr: 2
      transaction.state.log.replication.factor: 3
    jmxOptions:
      '-Xms': 8192m
      '-Xmx': 8192m
    listeners:
      plain: {}
      tls: {}
      external:
        type: nodeport
        tls: false
    replicas: 3
    resources:
      limits:
        cpu: '1'
        memory: 1Gi
      requests:
        cpu: 500m
        memory: 500Mi
    storage:
      type: ephemeral
    version: 2.5.0
  zookeeper:
    jmxOptions:
      '-Xms': 4096m
      '-Xmx': 4096m
    replicas: 3
    resources:
      limits:
        cpu: '1'
        memory: 1000Mi
      requests:
        cpu: 500m
        memory: 500Mi
    storage:
      type: ephemeral


$ cat /tmp/strimzi.properties
##############################
##############################
# This file is automatically generated by the Strimzi Cluster Operator
# Any changes to this file will be ignored and overwritten!
##############################
##############################

##########
# Broker ID
##########
broker.id=0

##########
# Zookeeper
##########
zookeeper.connect=localhost:2181

##########
# Kafka message logs configuration
##########
log.dirs=/var/lib/kafka/data/kafka-log0

##########
# Replication listener
##########
# cluster-ca-certs                         ->  /tmp/kafka/cluster.truststore.p12
# broker-certs                             ->  /tmp/kafka/cluster.keystore.p12
# certificates/custom-tls-9093-certs       ->  /tmp/kafka/custom-tls-9093.keystore.p12
# certificates/custom-external-9094-certs  ->  /tmp/kafka/custom-external-9094.keystore.p12
# client-ca-certs                          ->  /tmp/kafka/clients.truststore.p12
# certificates/oauth-plain-9092-certs      ->  /tmp/kafka/oauth-plain-9092.truststore.p12
# certificates/oauth-tls-9093-certs        ->  /tmp/kafka/oauth-tls-9093.truststore.p12
# certificates/oauth-external-9094-certs   ->  /tmp/kafka/oauth-external-9094.truststore.p12
# certificates/authz-keycloak-certs        ->  /tmp/kafka/authz-keycloak.truststore.p12

listener.name.replication-9091.ssl.keystore.location=/tmp/kafka/cluster.keystore.p12
listener.name.replication-9091.ssl.keystore.password=LGvvd5m483XnuIKaLlGxMpNJeAKkBkju
listener.name.replication-9091.ssl.keystore.type=PKCS12
listener.name.replication-9091.ssl.truststore.location=/tmp/kafka/cluster.truststore.p12
listener.name.replication-9091.ssl.truststore.password=LGvvd5m483XnuIKaLlGxMpNJeAKkBkju
listener.name.replication-9091.ssl.truststore.type=PKCS12
listener.name.replication-9091.ssl.client.auth=required

##########
# Plain listener
##########

##########
# TLS listener
##########
listener.name.tls-9093.ssl.keystore.location=/tmp/kafka/cluster.keystore.p12
listener.name.tls-9093.ssl.keystore.password=LGvvd5m483XnuIKaLlGxMpNJeAKkBkju
listener.name.tls-9093.ssl.keystore.type=PKCS12

##########
# External listener
##########
##########
# Common listener configuration
##########
listeners=
REPLICATION-9091://0.0.0.0:9091,
PLAIN-9092://0.0.0.0:9092,
TLS-9093://0.0.0.0:9093,
EXTERNAL-9094://0.0.0.0:9094

advertised.listeners=
REPLICATION-9091://my-cluster-kafka-0.my-cluster-kafka-brokers.hz-kafka.svc:9091,
PLAIN-9092://my-cluster-kafka-0.my-cluster-kafka-brokers.hz-kafka.svc:9092,
TLS-9093://my-cluster-kafka-0.my-cluster-kafka-brokers.hz-kafka.svc:9093,
EXTERNAL-9094://192.168.132.208:31784

listener.security.protocol.map=REPLICATION-9091:SSL,PLAIN-9092:PLAINTEXT,TLS-9093:SSL,EXTERNAL-9094:PLAINTEXT
inter.broker.listener.name=REPLICATION-9091
sasl.enabled.mechanisms=
ssl.secure.random.implementation=SHA1PRNG
ssl.endpoint.identification.algorithm=HTTPS

##########
# User provided configuration
##########
log.message.format.version=2.5
offsets.topic.replication.factor=3
transaction.state.log.min.isr=2
transaction.state.log.replication.factor=3
```


## 组合1

```yaml
# 创建 Kafka 集群的 yaml 文件
apiVersion: kafka.strimzi.io/v1beta1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    version: 2.5.0
    replicas: 3
    jmxOptions: {}
    listeners:
      plain:
        authentication:
          type: scram-sha-512
    authorization:
      type: simple
    config:
      offsets.topic.replication.factor: 3
      transaction.state.log.replication.factor: 3
      transaction.state.log.min.isr: 2
      log.message.format.version: '2.5'
    storage:
      type: ephemeral
  zookeeper:
    replicas: 3
    storage:
      type: ephemeral
  entityOperator:
    topicOperator: {}
    userOperator: {}

---

# 创建 KafkaUser 集群的 yaml 文件
apiVersion: kafka.strimzi.io/v1beta1
kind: KafkaUser
metadata:
  name: my-user
  labels:
    strimzi.io/cluster: my-cluster
spec:
  authentication:
    type: scram-sha-512
  authorization:
    type: simple
    acls:
      - resource:
          type: topic
          name: my-topic
          patternType: literal
        operation: Read
        host: '*'
      - resource:
          type: topic
          name: my-topic
          patternType: literal
        operation: Describe
        host: '*'
      - resource:
          type: group
          name: my-group
          patternType: literal
        operation: Read
        host: '*'
      - resource:
          type: topic
          name: my-topic
          patternType: literal
        operation: Write
        host: '*'
      - resource:
          type: topic
          name: my-topic
          patternType: literal
        operation: Create
        host: '*'
      - resource:
          type: topic
          name: my-topic
          patternType: literal
        operation: Describe
        host: '*'


---

# 创建 KafkaTopic 集群的 yaml 文件
apiVersion: kafka.strimzi.io/v1beta1
kind: KafkaTopic
metadata:
  name: my-topic
  labels:
    strimzi.io/cluster: my-cluster
spec:
  partitions: 3
  replicas: 3
  config:
    retention.ms: 604800000
    segment.bytes: 1073741824



##############################
##############################
# This file is automatically generated by the Strimzi Cluster Operator
# Any changes to this file will be ignored and overwritten!
##############################
##############################

##########
# Broker ID
##########
broker.id=0

##########
# Zookeeper
##########
zookeeper.connect=localhost:2181

##########
# Kafka message logs configuration
##########
log.dirs=/var/lib/kafka/data/kafka-log0

##########
# Replication listener
##########
# cluster-ca-certs                         ->  /tmp/kafka/cluster.truststore.p12
# broker-certs                             ->  /tmp/kafka/cluster.keystore.p12
# certificates/custom-tls-9093-certs       ->  /tmp/kafka/custom-tls-9093.keystore.p12
# certificates/custom-external-9094-certs  ->  /tmp/kafka/custom-external-9094.keystore.p12
# client-ca-certs                          ->  /tmp/kafka/clients.truststore.p12
# certificates/oauth-plain-9092-certs      ->  /tmp/kafka/oauth-plain-9092.truststore.p12
# certificates/oauth-tls-9093-certs        ->  /tmp/kafka/oauth-tls-9093.truststore.p12
# certificates/oauth-external-9094-certs   ->  /tmp/kafka/oauth-external-9094.truststore.p12
# certificates/authz-keycloak-certs        ->  /tmp/kafka/authz-keycloak.truststore.p12

listener.name.replication-9091.ssl.keystore.location=/tmp/kafka/cluster.keystore.p12
listener.name.replication-9091.ssl.keystore.password=TG86aakg81bCmH7R-MHFu8uqybQKwSqa
listener.name.replication-9091.ssl.keystore.type=PKCS12
listener.name.replication-9091.ssl.truststore.location=/tmp/kafka/cluster.truststore.p12
listener.name.replication-9091.ssl.truststore.password=TG86aakg81bCmH7R-MHFu8uqybQKwSqa
listener.name.replication-9091.ssl.truststore.type=PKCS12
listener.name.replication-9091.ssl.client.auth=required

##########
# Plain listener
##########
listener.name.plain-9092.scram-sha-512.sasl.jaas.config=org.apache.kafka.common.security.scram.ScramLoginModule required;
listener.name.plain-9092.sasl.enabled.mechanisms=SCRAM-SHA-512


##########
# Common listener configuration
##########
listeners=REPLICATION-9091://0.0.0.0:9091,PLAIN-9092://0.0.0.0:9092
advertised.listeners=REPLICATION-9091://my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc:9091,PLAIN-9092://my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc:9092
listener.security.protocol.map=REPLICATION-9091:SSL,PLAIN-9092:SASL_PLAINTEXT
inter.broker.listener.name=REPLICATION-9091
sasl.enabled.mechanisms=
ssl.secure.random.implementation=SHA1PRNG
ssl.endpoint.identification.algorithm=HTTPS

##########
# Authorization
##########
authorizer.class.name=kafka.security.auth.SimpleAclAuthorizer
super.users=User:CN=my-cluster-kafka,O=io.strimzi;User:CN=my-cluster-entity-operator,O=io.strimzi;User:CN=my-cluster-kafka-exporter,O=io.strimzi;User:CN=my-cluster-cruise-control,O=io.strimzi;User:CN=cluster-operator,O=io.strimzi

##########
# User provided configuration
##########
log.message.format.version=2.5
offsets.topic.replication.factor=3
transaction.state.log.min.isr=2
transaction.state.log.replication.factor=3
```

验证结果：

```bash
# 获取 my-user 用户密码
$ kubectl -n operators get secret my-user -o jsonpath='{.data.password}' | base64 -d
DnZbkwsrzU6V

# 创建生产者和消费者客户端连接配置文件，注意用户密码
$ cat << EOF > client.properties
sasl.jaas.config=org.apache.kafka.common.security.scram.ScramLoginModule required \
    username="my-user" \
    password="DnZbkwsrzU6V";

security.protocol=SASL_PLAINTEXT
sasl.mechanism=SCRAM-SHA-512
EOF

# 创建 pod 作为生产者和消费者客户端
$ kubectl -n operators run kafka-test -ti --image=172.16.3.34:60080/tdsql/kafka/release/0.18.0/kafka:0.18.0-kafka-2.5.0-v3.4.0 --image-pull-policy='IfNotPresent' --rm=true --restart=Never bash

# 将相关文件复制到 pod 中
$ kubectl -n operators cp client.properties kafka-test:/home/kafka/

# 进入 pod 运行生产者
$ kubeclt -n kafka exec -ti kafka-test bash
$ cd /home/kafka/
$ /opt/kafka/bin/kafka-topics.sh --bootstrap-server my-cluster-kafka-bootstrap:9092 --command-config ./client.properties --list
$ /opt/kafka/bin/kafka-console-producer.sh --bootstrap-server my-cluster-kafka-bootstrap:9092 --topic my-topic --producer.config ./client.properties
>hello1
>hello2
>hello3
>hello4
>

# 进入 pod 运行消费者
$ kubeclt -n kafka exec -ti kafka-test bash
$ cd /home/kafka/
$ /opt/kafka/bin/kafka-console-consumer.sh --bootstrap-server my-cluster-kafka-bootstrap:9092 --topic my-topic --consumer.config ./client.properties --from-beginning --group my-group
hello1
hello2
hello3
hello4
```


## 组合2

```yaml
# 创建 Kafka 集群的 yaml 文件
apiVersion: kafka.strimzi.io/v1beta1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    version: 2.5.0
    replicas: 3
    jmxOptions: {}
    listeners:
      tls:
        authentication:
          type: scram-sha-512
    authorization:
      type: simple
    config:
      offsets.topic.replication.factor: 3
      transaction.state.log.replication.factor: 3
      transaction.state.log.min.isr: 2
      log.message.format.version: '2.5'
    storage:
      type: ephemeral
  zookeeper:
    replicas: 3
    storage:
      type: ephemeral
  entityOperator:
    topicOperator: {}
    userOperator: {}

---

# 创建 KafkaUser 集群的 yaml 文件
apiVersion: kafka.strimzi.io/v1beta1
kind: KafkaUser
metadata:
  name: my-user
  labels:
    strimzi.io/cluster: my-cluster
spec:
  authentication:
    type: scram-sha-512
  authorization:
    type: simple
    acls:
      - resource:
          type: topic
          name: my-topic
          patternType: literal
        operation: Read
        host: '*'
      - resource:
          type: topic
          name: my-topic
          patternType: literal
        operation: Describe
        host: '*'
      - resource:
          type: group
          name: my-group
          patternType: literal
        operation: Read
        host: '*'
      - resource:
          type: topic
          name: my-topic
          patternType: literal
        operation: Write
        host: '*'
      - resource:
          type: topic
          name: my-topic
          patternType: literal
        operation: Create
        host: '*'
      - resource:
          type: topic
          name: my-topic
          patternType: literal
        operation: Describe
        host: '*'

---

# 创建 KafkaTopic 集群的 yaml 文件
apiVersion: kafka.strimzi.io/v1beta1
kind: KafkaTopic
metadata:
  name: my-topic
  labels:
    strimzi.io/cluster: my-cluster
spec:
  partitions: 3
  replicas: 3
  config:
    retention.ms: 604800000
    segment.bytes: 1073741824



##############################
##############################
# This file is automatically generated by the Strimzi Cluster Operator
# Any changes to this file will be ignored and overwritten!
##############################
##############################

##########
# Broker ID
##########
broker.id=0

##########
# Zookeeper
##########
zookeeper.connect=localhost:2181

##########
# Kafka message logs configuration
##########
log.dirs=/var/lib/kafka/data/kafka-log0

##########
# Replication listener
##########
# cluster-ca-certs                         ->  /tmp/kafka/cluster.truststore.p12
# broker-certs                             ->  /tmp/kafka/cluster.keystore.p12
# certificates/custom-tls-9093-certs       ->  /tmp/kafka/custom-tls-9093.keystore.p12
# certificates/custom-external-9094-certs  ->  /tmp/kafka/custom-external-9094.keystore.p12
# client-ca-certs                          ->  /tmp/kafka/clients.truststore.p12
# certificates/oauth-plain-9092-certs      ->  /tmp/kafka/oauth-plain-9092.truststore.p12
# certificates/oauth-tls-9093-certs        ->  /tmp/kafka/oauth-tls-9093.truststore.p12
# certificates/oauth-external-9094-certs   ->  /tmp/kafka/oauth-external-9094.truststore.p12
# certificates/authz-keycloak-certs        ->  /tmp/kafka/authz-keycloak.truststore.p12

listener.name.replication-9091.ssl.keystore.location=/tmp/kafka/cluster.keystore.p12
listener.name.replication-9091.ssl.keystore.password=bkvi3Kngwkp55Yi2CFbqM7TtdK81wihX
listener.name.replication-9091.ssl.keystore.type=PKCS12
listener.name.replication-9091.ssl.truststore.location=/tmp/kafka/cluster.truststore.p12
listener.name.replication-9091.ssl.truststore.password=bkvi3Kngwkp55Yi2CFbqM7TtdK81wihX
listener.name.replication-9091.ssl.truststore.type=PKCS12
listener.name.replication-9091.ssl.client.auth=required

##########
# TLS listener
##########
listener.name.tls-9093.scram-sha-512.sasl.jaas.config=org.apache.kafka.common.security.scram.ScramLoginModule required;
listener.name.tls-9093.sasl.enabled.mechanisms=SCRAM-SHA-512

listener.name.tls-9093.ssl.keystore.location=/tmp/kafka/cluster.keystore.p12
listener.name.tls-9093.ssl.keystore.password=bkvi3Kngwkp55Yi2CFbqM7TtdK81wihX
listener.name.tls-9093.ssl.keystore.type=PKCS12

##########
# Common listener configuration
##########
listeners=REPLICATION-9091://0.0.0.0:9091,TLS-9093://0.0.0.0:9093
advertised.listeners=REPLICATION-9091://my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc:9091,TLS-9093://my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc:9093
listener.security.protocol.map=REPLICATION-9091:SSL,TLS-9093:SASL_SSL
inter.broker.listener.name=REPLICATION-9091
sasl.enabled.mechanisms=
ssl.secure.random.implementation=SHA1PRNG
ssl.endpoint.identification.algorithm=HTTPS

##########
# Authorization
##########
authorizer.class.name=kafka.security.auth.SimpleAclAuthorizer
super.users=User:CN=my-cluster-kafka,O=io.strimzi;User:CN=my-cluster-entity-operator,O=io.strimzi;User:CN=my-cluster-kafka-exporter,O=io.strimzi;User:CN=my-cluster-cruise-control,O=io.strimzi;User:CN=cluster-operator,O=io.strimzi

##########
# User provided configuration
##########
log.message.format.version=2.5
offsets.topic.replication.factor=3
transaction.state.log.min.isr=2
transaction.state.log.replication.factor=3
```

验证结果：

```bash
# 获取 CA 证书
$ kubectl -n operators get secret my-cluster-cluster-ca-cert -o jsonpath='{.data.ca\.crt}' | base64 -d > ca.crt

# 获取 CA 证书密码
$ kubectl -n operators get secret my-cluster-cluster-ca-cert -o jsonpath='{.data.ca\.password}' | base64 -d
KeYLZ1mXzVJD

# 将 CA 证书导入 user-truststore.jks 文件中
$ keytool -keystore user-truststore.jks -alias CARoot -import -file ca.crt

# 获取 my-user 用户密码
$ kubectl -n operators get secret my-user -o jsonpath='{.data.password}' | base64 -d
aVKJfULKJdRh

# 创建生产者和消费者客户端连接配置文件，注意用户密码，CA 证书密码
$ cat << EOF > client.properties
security.protocol=SSL
ssl.truststore.location=/home/kafka/user-truststore.jks
ssl.truststore.password=KeYLZ1mXzVJD

sasl.jaas.config=org.apache.kafka.common.security.scram.ScramLoginModule required \
    username="my-user" \
    password="aVKJfULKJdRh";

security.protocol=SASL_SSL
sasl.mechanism=SCRAM-SHA-512
EOF


# 创建 pod 作为生产者和消费者客户端
$ kubectl -n operators run kafka-test -ti --image=172.16.3.34:60080/tdsql/kafka/release/0.18.0/kafka:0.18.0-kafka-2.5.0-v3.4.0 --rm=true --restart=Never bash

# 将相关文件复制到 pod 中
$ kubectl -n operators cp client.properties kafka-test:/home/kafka/
$ kubectl -n operators cp user-truststore.jks kafka-test:/home/kafka/

# 进入 pod 运行生产者
$ kubeclt -n kafka exec -ti kafka-test bash
$ cd /home/kafka/

$ /opt/kafka/bin/kafka-topics.sh --bootstrap-server my-cluster-kafka-bootstrap:9093 --command-config ./client.properties --list

$ /opt/kafka/bin/kafka-console-producer.sh --bootstrap-server my-cluster-kafka-bootstrap:9093 --topic my-topic --producer.config ./client.properties
>hello1
>hello2
>hello3
>hello4
>

# 进入 pod 运行消费者
$ kubeclt -n kafka exec -ti kafka-test bash
$ cd /home/kafka/
$ /opt/kafka/bin/kafka-console-consumer.sh --bootstrap-server my-cluster-kafka-bootstrap:9093 --topic my-topic --consumer.config ./client.properties --from-beginning --group my-group
hello1
hello2
hello3
hello4
```

## 组合3

```yaml
# 创建 Kafka 集群的 yaml 文件
apiVersion: kafka.strimzi.io/v1beta1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    version: 2.5.0
    replicas: 3
    jmxOptions: {}
    listeners:
      tls:
        authentication:
          type: tls
    authorization:
      type: simple
    config:
      offsets.topic.replication.factor: 3
      transaction.state.log.replication.factor: 3
      transaction.state.log.min.isr: 2
      log.message.format.version: '2.5'
    storage:
      type: ephemeral
  zookeeper:
    replicas: 3
    storage:
      type: ephemeral
  entityOperator:
    topicOperator: {}
    userOperator: {}

---

# 创建 KafkaUser 集群的 yaml 文件
apiVersion: kafka.strimzi.io/v1beta1
kind: KafkaUser
metadata:
  name: my-user
  labels:
    strimzi.io/cluster: my-cluster
spec:
  authentication:
    type: tls
  authorization:
    type: simple
    acls:
      - resource:
          type: topic
          name: my-topic
          patternType: literal
        operation: Read
        host: '*'
      - resource:
          type: topic
          name: my-topic
          patternType: literal
        operation: Describe
        host: '*'
      - resource:
          type: group
          name: my-group
          patternType: literal
        operation: Read
        host: '*'
      - resource:
          type: topic
          name: my-topic
          patternType: literal
        operation: Write
        host: '*'
      - resource:
          type: topic
          name: my-topic
          patternType: literal
        operation: Create
        host: '*'
      - resource:
          type: topic
          name: my-topic
          patternType: literal
        operation: Describe
        host: '*'

---

# 创建 KafkaTopic 集群的 yaml 文件
apiVersion: kafka.strimzi.io/v1beta1
kind: KafkaTopic
metadata:
  name: my-topic
  labels:
    strimzi.io/cluster: my-cluster
spec:
  partitions: 3
  replicas: 3
  config:
    retention.ms: 604800000
    segment.bytes: 1073741824


##############################
##############################
# This file is automatically generated by the Strimzi Cluster Operator
# Any changes to this file will be ignored and overwritten!
##############################
##############################

##########
# Broker ID
##########
broker.id=0

##########
# Zookeeper
##########
zookeeper.connect=localhost:2181

##########
# Kafka message logs configuration
##########
log.dirs=/var/lib/kafka/data/kafka-log0

##########
# Replication listener
##########
# cluster-ca-certs                         ->  /tmp/kafka/cluster.truststore.p12
# broker-certs                             ->  /tmp/kafka/cluster.keystore.p12
# certificates/custom-tls-9093-certs       ->  /tmp/kafka/custom-tls-9093.keystore.p12
# certificates/custom-external-9094-certs  ->  /tmp/kafka/custom-external-9094.keystore.p12
# client-ca-certs                          ->  /tmp/kafka/clients.truststore.p12
# certificates/oauth-plain-9092-certs      ->  /tmp/kafka/oauth-plain-9092.truststore.p12
# certificates/oauth-tls-9093-certs        ->  /tmp/kafka/oauth-tls-9093.truststore.p12
# certificates/oauth-external-9094-certs   ->  /tmp/kafka/oauth-external-9094.truststore.p12
# certificates/authz-keycloak-certs        ->  /tmp/kafka/authz-keycloak.truststore.p12

listener.name.replication-9091.ssl.keystore.location=/tmp/kafka/cluster.keystore.p12
listener.name.replication-9091.ssl.keystore.password=yJoQri4MaTcO-ptNUern-WU7aYx4qphc
listener.name.replication-9091.ssl.keystore.type=PKCS12
listener.name.replication-9091.ssl.truststore.location=/tmp/kafka/cluster.truststore.p12
listener.name.replication-9091.ssl.truststore.password=yJoQri4MaTcO-ptNUern-WU7aYx4qphc
listener.name.replication-9091.ssl.truststore.type=PKCS12
listener.name.replication-9091.ssl.client.auth=required

##########
# TLS listener
##########
listener.name.tls-9093.ssl.client.auth=required
listener.name.tls-9093.ssl.truststore.location=/tmp/kafka/clients.truststore.p12
listener.name.tls-9093.ssl.truststore.password=yJoQri4MaTcO-ptNUern-WU7aYx4qphc
listener.name.tls-9093.ssl.truststore.type=PKCS12

listener.name.tls-9093.ssl.keystore.location=/tmp/kafka/cluster.keystore.p12
listener.name.tls-9093.ssl.keystore.password=yJoQri4MaTcO-ptNUern-WU7aYx4qphc
listener.name.tls-9093.ssl.keystore.type=PKCS12

##########
# Common listener configuration
##########
listeners=REPLICATION-9091://0.0.0.0:9091,TLS-9093://0.0.0.0:9093
advertised.listeners=REPLICATION-9091://my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc:9091,TLS-9093://my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc:9093
listener.security.protocol.map=REPLICATION-9091:SSL,TLS-9093:SSL
inter.broker.listener.name=REPLICATION-9091
sasl.enabled.mechanisms=
ssl.secure.random.implementation=SHA1PRNG
ssl.endpoint.identification.algorithm=HTTPS

##########
# Authorization
##########
authorizer.class.name=kafka.security.auth.SimpleAclAuthorizer
super.users=User:CN=my-cluster-kafka,O=io.strimzi;User:CN=my-cluster-entity-operator,O=io.strimzi;User:CN=my-cluster-kafka-exporter,O=io.strimzi;User:CN=my-cluster-cruise-control,O=io.strimzi;User:CN=cluster-operator,O=io.strimzi

##########
# User provided configuration
##########
log.message.format.version=2.5
offsets.topic.replication.factor=3
transaction.state.log.min.isr=2
transaction.state.log.replication.factor=3
```

验证结果：

```bash
# 获取 CA 证书
$ kubectl -n operators get secret my-cluster-cluster-ca-cert -o jsonpath='{.data.ca\.crt}' | base64 -d > ca.crt

# 获取 CA 证书密码
$ kubectl -n operators get secret my-cluster-cluster-ca-cert -o jsonpath='{.data.ca\.password}' | base64 -d
yI1200KfYCIx

# 将 CA 证书导入 user-truststore.jks 文件中
$ keytool -keystore user-truststore.jks -alias CARoot -import -file ca.crt


# 获取用户证书
$ kubectl -n operators get secret my-user -o jsonpath='{.data.user\.p12}' | base64 -d > user.p12

# 获取用户证书密码
$ kubectl -n operators get secret my-user -o jsonpath='{.data.user\.password}' | base64 -d
DBGWCCLw4JJ6

# 将用户证书导入 user-keystore.jks 文件中
$ keytool -importkeystore -srckeystore user.p12 -destkeystore user-keystore.jks -deststoretype pkcs12

# 创建生产者和消费者客户端连接配置文件，注意用户证书密码，CA 证书密码
cat << EOF > client-ssl.properties
security.protocol=SSL
ssl.truststore.location=/home/kafka/user-truststore.jks
ssl.truststore.password=yI1200KfYCIx

ssl.keystore.location=/home/kafka/user-keystore.jks
ssl.keystore.password=DBGWCCLw4JJ6
ssl.key.password=DBGWCCLw4JJ6
EOF


# 创建 pod 作为生产者和消费者客户端
$ kubectl -n operators run kafka-test -ti --image=172.16.3.34:60080/tdsql/kafka/release/0.18.0/kafka:0.18.0-kafka-2.5.0-v3.4.0 --rm=true --restart=Never bash

# 将相关文件复制到 pod 中
$ kubectl -n operators cp client-ssl.properties kafka-test:/home/kafka/
$ kubectl -n operators cp user-keystore.jks kafka-test:/home/kafka/
$ kubectl -n operators cp user-truststore.jks kafka-test:/home/kafka/


# 进入 pod 运行生产者
$ kubeclt -n kafka exec -ti kafka-test bash
$ cd /home/kafka/

$ /opt/kafka/bin/kafka-topics.sh --bootstrap-server my-cluster-kafka-bootstrap:9093 --command-config ./client-ssl.properties --list

$ /opt/kafka/bin/kafka-console-producer.sh --bootstrap-server my-cluster-kafka-bootstrap:9093 --topic my-topic --producer.config ./client-ssl.properties
>hello1
>hello2
>hello3
>hello4
>

# 进入 pod 运行消费者
$ kubeclt -n kafka exec -ti kafka-test bash
$ cd /home/kafka/
$ /opt/kafka/bin/kafka-console-consumer.sh --bootstrap-server my-cluster-kafka-bootstrap:9093 --topic my-topic --consumer.config ./client-ssl.properties --from-beginning --group my-group
hello1
hello2
hello3
hello4
```

参考：

* https://github.com/strimzi/strimzi-kafka-operator/issues/3036

## 组合四

```yaml
# 创建 Kafka 集群的 yaml 文件
apiVersion: kafka.strimzi.io/v1beta1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    version: 2.5.0
    replicas: 3
    jmxOptions: {}
    listeners:
      external:
        type: nodeport
        tls: false
        authentication:
          type: scram-sha-512
    authorization:
      type: simple
    config:
      offsets.topic.replication.factor: 3
      transaction.state.log.replication.factor: 3
      transaction.state.log.min.isr: 2
      log.message.format.version: '2.5'
    storage:
      type: ephemeral
  zookeeper:
    replicas: 3
    storage:
      type: ephemeral
  entityOperator:
    topicOperator: {}
    userOperator: {}

---

# 创建 KafkaUser 集群的 yaml 文件
apiVersion: kafka.strimzi.io/v1beta1
kind: KafkaUser
metadata:
  name: my-user
  labels:
    strimzi.io/cluster: my-cluster
spec:
  authentication:
    type: scram-sha-512
  authorization:
    type: simple
    acls:
      - resource:
          type: topic
          name: my-topic
          patternType: literal
        operation: Read
        host: '*'
      - resource:
          type: topic
          name: my-topic
          patternType: literal
        operation: Describe
        host: '*'
      - resource:
          type: group
          name: my-group
          patternType: literal
        operation: Read
        host: '*'
      - resource:
          type: topic
          name: my-topic
          patternType: literal
        operation: Write
        host: '*'
      - resource:
          type: topic
          name: my-topic
          patternType: literal
        operation: Create
        host: '*'
      - resource:
          type: topic
          name: my-topic
          patternType: literal
        operation: Describe
        host: '*'

---

# 创建 KafkaTopic 集群的 yaml 文件
apiVersion: kafka.strimzi.io/v1beta1
kind: KafkaTopic
metadata:
  name: my-topic
  labels:
    strimzi.io/cluster: my-cluster
spec:
  partitions: 3
  replicas: 3
  config:
    retention.ms: 604800000
    segment.bytes: 1073741824

##############################
##############################
# This file is automatically generated by the Strimzi Cluster Operator
# Any changes to this file will be ignored and overwritten!
##############################
##############################

##########
# Broker ID
##########
broker.id=0

##########
# Zookeeper
##########
zookeeper.connect=localhost:2181

##########
# Kafka message logs configuration
##########
log.dirs=/var/lib/kafka/data/kafka-log0

##########
# Replication listener
##########
# cluster-ca-certs                         ->  /tmp/kafka/cluster.truststore.p12
# broker-certs                             ->  /tmp/kafka/cluster.keystore.p12
# certificates/custom-tls-9093-certs       ->  /tmp/kafka/custom-tls-9093.keystore.p12
# certificates/custom-external-9094-certs  ->  /tmp/kafka/custom-external-9094.keystore.p12
# client-ca-certs                          ->  /tmp/kafka/clients.truststore.p12
# certificates/oauth-plain-9092-certs      ->  /tmp/kafka/oauth-plain-9092.truststore.p12
# certificates/oauth-tls-9093-certs        ->  /tmp/kafka/oauth-tls-9093.truststore.p12
# certificates/oauth-external-9094-certs   ->  /tmp/kafka/oauth-external-9094.truststore.p12
# certificates/authz-keycloak-certs        ->  /tmp/kafka/authz-keycloak.truststore.p12

listener.name.replication-9091.ssl.keystore.location=/tmp/kafka/cluster.keystore.p12
listener.name.replication-9091.ssl.keystore.password=LdqIyA4_7NFcp9x0ZHrDJJMgXkYzTVak
listener.name.replication-9091.ssl.keystore.type=PKCS12
listener.name.replication-9091.ssl.truststore.location=/tmp/kafka/cluster.truststore.p12
listener.name.replication-9091.ssl.truststore.password=LdqIyA4_7NFcp9x0ZHrDJJMgXkYzTVak
listener.name.replication-9091.ssl.truststore.type=PKCS12
listener.name.replication-9091.ssl.client.auth=required

##########
# External listener
##########
listener.name.external-9094.scram-sha-512.sasl.jaas.config=org.apache.kafka.common.security.scram.ScramLoginModule required;
listener.name.external-9094.sasl.enabled.mechanisms=SCRAM-SHA-512

##########
# Common listener configuration
##########
listeners=REPLICATION-9091://0.0.0.0:9091,EXTERNAL-9094://0.0.0.0:9094
advertised.listeners=REPLICATION-9091://my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc:9091,EXTERNAL-9094://10.0.128.175:32536
listener.security.protocol.map=REPLICATION-9091:SSL,EXTERNAL-9094:SASL_PLAINTEXT
inter.broker.listener.name=REPLICATION-9091
sasl.enabled.mechanisms=
ssl.secure.random.implementation=SHA1PRNG
ssl.endpoint.identification.algorithm=HTTPS

##########
# Authorization
##########
authorizer.class.name=kafka.security.auth.SimpleAclAuthorizer
super.users=User:CN=my-cluster-kafka,O=io.strimzi;User:CN=my-cluster-entity-operator,O=io.strimzi;User:CN=my-cluster-kafka-exporter,O=io.strimzi;User:CN=my-cluster-cruise-control,O=io.strimzi;User:CN=cluster-operator,O=io.strimzi

##########
# User provided configuration
##########
log.message.format.version=2.5
offsets.topic.replication.factor=3
transaction.state.log.min.isr=2
transaction.state.log.replication.factor=3
```

验证结果：

```bash
# 获取 my-user 用户密码
$ kubectl -n kafka get secret my-user -o jsonpath='{.data.password}' | base64 -d
p1ZZpYSfmRiI


# 创建生产者和消费者客户端连接配置文件，注意用户密码
$ cat << EOF > client.properties
sasl.jaas.config=org.apache.kafka.common.security.scram.ScramLoginModule required \
    username="my-user" \
    password="p1ZZpYSfmRiI";

security.protocol=SASL_PLAINTEXT
sasl.mechanism=SCRAM-SHA-512
EOF

# 生产者
$ kafka-console-producer.sh --bootstrap-server 10.0.128.202:31189 --topic my-topic --producer.config ./client.properties
>hello1
>hello2
>

# 消费者
$ kafka-console-consumer.sh --bootstrap-server 10.0.128.202:31189 --topic my-topic --consumer.config ./client.properties --from-beginning --group my-group
hello1
hello2
```

## 组合五

```yaml
# 创建 Kafka 集群的 yaml 文件
apiVersion: kafka.strimzi.io/v1beta1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    version: 2.5.0
    replicas: 3
    jmxOptions: {}
    listeners:
      external:
        type: nodeport
        tls: true
        authentication:
          type: scram-sha-512
    authorization:
      type: simple
    config:
      offsets.topic.replication.factor: 3
      transaction.state.log.replication.factor: 3
      transaction.state.log.min.isr: 2
      log.message.format.version: '2.5'
    storage:
      type: ephemeral
  zookeeper:
    replicas: 3
    storage:
      type: ephemeral
  entityOperator:
    topicOperator: {}
    userOperator: {}

---

# 创建 KafkaUser 集群的 yaml 文件
apiVersion: kafka.strimzi.io/v1beta1
kind: KafkaUser
metadata:
  name: my-user
  labels:
    strimzi.io/cluster: my-cluster
spec:
  authentication:
    type: scram-sha-512
  authorization:
    type: simple
    acls:
      - resource:
          type: topic
          name: my-topic
          patternType: literal
        operation: Read
        host: '*'
      - resource:
          type: topic
          name: my-topic
          patternType: literal
        operation: Describe
        host: '*'
      - resource:
          type: group
          name: my-group
          patternType: literal
        operation: Read
        host: '*'
      - resource:
          type: topic
          name: my-topic
          patternType: literal
        operation: Write
        host: '*'
      - resource:
          type: topic
          name: my-topic
          patternType: literal
        operation: Create
        host: '*'
      - resource:
          type: topic
          name: my-topic
          patternType: literal
        operation: Describe
        host: '*'

---

# 创建 KafkaTopic 集群的 yaml 文件
apiVersion: kafka.strimzi.io/v1beta1
kind: KafkaTopic
metadata:
  name: my-topic
  labels:
    strimzi.io/cluster: my-cluster
spec:
  partitions: 3
  replicas: 3
  config:
    retention.ms: 604800000
    segment.bytes: 1073741824

##############################
##############################
# This file is automatically generated by the Strimzi Cluster Operator
# Any changes to this file will be ignored and overwritten!
##############################
##############################

##########
# Broker ID
##########
broker.id=0

##########
# Zookeeper
##########
zookeeper.connect=localhost:2181

##########
# Kafka message logs configuration
##########
log.dirs=/var/lib/kafka/data/kafka-log0

##########
# Replication listener
##########
# cluster-ca-certs                         ->  /tmp/kafka/cluster.truststore.p12
# broker-certs                             ->  /tmp/kafka/cluster.keystore.p12
# certificates/custom-tls-9093-certs       ->  /tmp/kafka/custom-tls-9093.keystore.p12
# certificates/custom-external-9094-certs  ->  /tmp/kafka/custom-external-9094.keystore.p12
# client-ca-certs                          ->  /tmp/kafka/clients.truststore.p12
# certificates/oauth-plain-9092-certs      ->  /tmp/kafka/oauth-plain-9092.truststore.p12
# certificates/oauth-tls-9093-certs        ->  /tmp/kafka/oauth-tls-9093.truststore.p12
# certificates/oauth-external-9094-certs   ->  /tmp/kafka/oauth-external-9094.truststore.p12
# certificates/authz-keycloak-certs        ->  /tmp/kafka/authz-keycloak.truststore.p12

listener.name.replication-9091.ssl.keystore.location=/tmp/kafka/cluster.keystore.p12
listener.name.replication-9091.ssl.keystore.password=p7JbjVuzmk1lFpjNS8PruuxKoCEAWEmn
listener.name.replication-9091.ssl.keystore.type=PKCS12
listener.name.replication-9091.ssl.truststore.location=/tmp/kafka/cluster.truststore.p12
listener.name.replication-9091.ssl.truststore.password=p7JbjVuzmk1lFpjNS8PruuxKoCEAWEmn
listener.name.replication-9091.ssl.truststore.type=PKCS12
listener.name.replication-9091.ssl.client.auth=required

##########
# External listener
##########
listener.name.external-9094.scram-sha-512.sasl.jaas.config=org.apache.kafka.common.security.scram.ScramLoginModule required;
listener.name.external-9094.sasl.enabled.mechanisms=SCRAM-SHA-512

listener.name.external-9094.ssl.keystore.location=/tmp/kafka/cluster.keystore.p12
listener.name.external-9094.ssl.keystore.password=p7JbjVuzmk1lFpjNS8PruuxKoCEAWEmn
listener.name.external-9094.ssl.keystore.type=PKCS12

##########
# Common listener configuration
##########
listeners=REPLICATION-9091://0.0.0.0:9091,EXTERNAL-9094://0.0.0.0:9094
advertised.listeners=REPLICATION-9091://my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc:9091,EXTERNAL-9094://10.0.128.175:31368
listener.security.protocol.map=REPLICATION-9091:SSL,EXTERNAL-9094:SASL_SSL
inter.broker.listener.name=REPLICATION-9091
sasl.enabled.mechanisms=
ssl.secure.random.implementation=SHA1PRNG
ssl.endpoint.identification.algorithm=HTTPS

##########
# Authorization
##########
authorizer.class.name=kafka.security.auth.SimpleAclAuthorizer
super.users=User:CN=my-cluster-kafka,O=io.strimzi;User:CN=my-cluster-entity-operator,O=io.strimzi;User:CN=my-cluster-kafka-exporter,O=io.strimzi;User:CN=my-cluster-cruise-control,O=io.strimzi;User:CN=cluster-operator,O=io.strimzi

##########
# User provided configuration
##########
log.message.format.version=2.5
offsets.topic.replication.factor=3
transaction.state.log.min.isr=2
transaction.state.log.replication.factor=3
```

验证结果：

```bash
# 获取 CA 证书
$ kubectl -n kafka get secret my-cluster-cluster-ca-cert -o jsonpath='{.data.ca\.crt}' | base64 -d > ca.crt

# 获取 CA 证书密码
$ kubectl -n kafka get secret my-cluster-cluster-ca-cert -o jsonpath='{.data.ca\.password}' | base64 -d
kgOg9JkSg7Qi

# 将 CA 证书导入 user-truststore.jks 文件中
$ keytool -keystore user-truststore.jks -alias CARoot -import -file ca.crt
输入密钥库口令: CA 证书密码 kgOg9JkSg7Qi
再次输入新口令: CA 证书密码 kgOg9JkSg7Qi
是否信任此证书? [否]:  y
证书已添加到密钥库中

# 获取 my-user 用户密码
$ kubectl -n kafka get secret my-user -o jsonpath='{.data.password}' | base64 -d
wasXcyTWsuOr


# 创建生产者和消费者客户端连接配置文件，注意用户密码，CA 证书密码
$ cat << EOF > client.properties
security.protocol=SSL
ssl.truststore.location=/root/ssl/user-truststore.jks
ssl.truststore.password=kgOg9JkSg7Qi
ssl.endpoint.identification.algorithm=

sasl.jaas.config=org.apache.kafka.common.security.scram.ScramLoginModule required \
    username="my-user" \
    password="wasXcyTWsuOr";

security.protocol=SASL_SSL
sasl.mechanism=SCRAM-SHA-512
EOF

# 生产者
$ kafka-console-producer.sh --bootstrap-server 10.0.128.202:30784 --topic my-topic --producer.config /root/ssl/client.properties
>hello1
>hello2
>hello3
>hello4
>

# 消费者
$ kafka-console-consumer.sh --bootstrap-server 10.0.128.202:30784 --topic my-topic --consumer.config /root/ssl/client.properties --from-beginning --group my-group
hello1
hello2
hello3
hello4
```

参考：

* https://github.com/strimzi/strimzi-kafka-operator/issues/3829

* https://github.com/strimzi/strimzi-kafka-operator/issues/1486

## 组合六

```yaml
# 创建 Kafka 集群的 yaml 文件
apiVersion: kafka.strimzi.io/v1beta1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    version: 2.5.0
    replicas: 3
    jmxOptions: {}
    listeners:
      external:
        type: nodeport
        tls: true
        authentication:
          type: tls
    authorization:
      type: simple
    config:
      offsets.topic.replication.factor: 3
      transaction.state.log.replication.factor: 3
      transaction.state.log.min.isr: 2
      log.message.format.version: '2.5'
    storage:
      type: ephemeral
  zookeeper:
    replicas: 3
    storage:
      type: ephemeral
  entityOperator:
    topicOperator: {}
    userOperator: {}

---

# 创建 KafkaUser 集群的 yaml 文件
apiVersion: kafka.strimzi.io/v1beta1
kind: KafkaUser
metadata:
  name: my-user
  labels:
    strimzi.io/cluster: my-cluster
spec:
  authentication:
    type: tls
  authorization:
    type: simple
    acls:
      - resource:
          type: topic
          name: my-topic
          patternType: literal
        operation: Read
        host: '*'
      - resource:
          type: topic
          name: my-topic
          patternType: literal
        operation: Describe
        host: '*'
      - resource:
          type: group
          name: my-group
          patternType: literal
        operation: Read
        host: '*'
      - resource:
          type: topic
          name: my-topic
          patternType: literal
        operation: Write
        host: '*'
      - resource:
          type: topic
          name: my-topic
          patternType: literal
        operation: Create
        host: '*'
      - resource:
          type: topic
          name: my-topic
          patternType: literal
        operation: Describe
        host: '*'

---

# 创建 KafkaTopic 集群的 yaml 文件
apiVersion: kafka.strimzi.io/v1beta1
kind: KafkaTopic
metadata:
  name: my-topic
  labels:
    strimzi.io/cluster: my-cluster
spec:
  partitions: 3
  replicas: 3
  config:
    retention.ms: 604800000
    segment.bytes: 1073741824


##############################
##############################
# This file is automatically generated by the Strimzi Cluster Operator
# Any changes to this file will be ignored and overwritten!
##############################
##############################

##########
# Broker ID
##########
broker.id=0

##########
# Zookeeper
##########
zookeeper.connect=localhost:2181

##########
# Kafka message logs configuration
##########
log.dirs=/var/lib/kafka/data/kafka-log0

##########
# Replication listener
##########
# cluster-ca-certs                         ->  /tmp/kafka/cluster.truststore.p12
# broker-certs                             ->  /tmp/kafka/cluster.keystore.p12
# certificates/custom-tls-9093-certs       ->  /tmp/kafka/custom-tls-9093.keystore.p12
# certificates/custom-external-9094-certs  ->  /tmp/kafka/custom-external-9094.keystore.p12
# client-ca-certs                          ->  /tmp/kafka/clients.truststore.p12
# certificates/oauth-plain-9092-certs      ->  /tmp/kafka/oauth-plain-9092.truststore.p12
# certificates/oauth-tls-9093-certs        ->  /tmp/kafka/oauth-tls-9093.truststore.p12
# certificates/oauth-external-9094-certs   ->  /tmp/kafka/oauth-external-9094.truststore.p12
# certificates/authz-keycloak-certs        ->  /tmp/kafka/authz-keycloak.truststore.p12

listener.name.replication-9091.ssl.keystore.location=/tmp/kafka/cluster.keystore.p12
listener.name.replication-9091.ssl.keystore.password=bOvUyWO66_f_WHvGMUl_hNlRu0H7N6jc
listener.name.replication-9091.ssl.keystore.type=PKCS12
listener.name.replication-9091.ssl.truststore.location=/tmp/kafka/cluster.truststore.p12
listener.name.replication-9091.ssl.truststore.password=bOvUyWO66_f_WHvGMUl_hNlRu0H7N6jc
listener.name.replication-9091.ssl.truststore.type=PKCS12
listener.name.replication-9091.ssl.client.auth=required

##########
# External listener
##########
listener.name.external-9094.ssl.client.auth=required
listener.name.external-9094.ssl.truststore.location=/tmp/kafka/clients.truststore.p12
listener.name.external-9094.ssl.truststore.password=bOvUyWO66_f_WHvGMUl_hNlRu0H7N6jc
listener.name.external-9094.ssl.truststore.type=PKCS12

listener.name.external-9094.ssl.keystore.location=/tmp/kafka/cluster.keystore.p12
listener.name.external-9094.ssl.keystore.password=bOvUyWO66_f_WHvGMUl_hNlRu0H7N6jc
listener.name.external-9094.ssl.keystore.type=PKCS12

##########
# Common listener configuration
##########
listeners=REPLICATION-9091://0.0.0.0:9091,EXTERNAL-9094://0.0.0.0:9094
advertised.listeners=REPLICATION-9091://my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc:9091,EXTERNAL-9094://10.0.128.47:30098
listener.security.protocol.map=REPLICATION-9091:SSL,EXTERNAL-9094:SSL
inter.broker.listener.name=REPLICATION-9091
sasl.enabled.mechanisms=
ssl.secure.random.implementation=SHA1PRNG
ssl.endpoint.identification.algorithm=HTTPS

##########
# Authorization
##########
authorizer.class.name=kafka.security.auth.SimpleAclAuthorizer
super.users=User:CN=my-cluster-kafka,O=io.strimzi;User:CN=my-cluster-entity-operator,O=io.strimzi;User:CN=my-cluster-kafka-exporter,O=io.strimzi;User:CN=my-cluster-cruise-control,O=io.strimzi;User:CN=cluster-operator,O=io.strimzi

##########
# User provided configuration
##########
log.message.format.version=2.5
offsets.topic.replication.factor=3
transaction.state.log.min.isr=2
transaction.state.log.replication.factor=3
```

验证结果：

```bash
# 获取 CA 证书
$ kubectl -n kafka get secret my-cluster-cluster-ca-cert -o jsonpath='{.data.ca\.crt}' | base64 -d > ca.crt

# 获取 CA 证书密码
$ kubectl -n kafka get secret my-cluster-cluster-ca-cert -o jsonpath='{.data.ca\.password}' | base64 -d
V27UGXKJ1c2a

# 将 CA 证书导入 user-truststore.jks 文件中
$ keytool -keystore user-truststore.jks -alias CARoot -import -file ca.crt
输入密钥库口令: CA 证书密码 V27UGXKJ1c2a
再次输入新口令: CA 证书密码 V27UGXKJ1c2a
是否信任此证书? [否]:  y
证书已添加到密钥库中


# 获取用户证书
$ kubectl -n kafka get secret my-user -o jsonpath='{.data.user\.p12}' | base64 -d > user.p12

# 获取用户证书密码
$ kubectl -n kafka get secret my-user -o jsonpath='{.data.user\.password}' | base64 -d
hU6HgL78Bw6x

# 将用户证书导入 user-keystore.jks 文件中
$ keytool -importkeystore -srckeystore user.p12 -destkeystore user-keystore.jks -deststoretype pkcs12
正在将密钥库 user.p12 导入到 user-keystore.jks...
输入目标密钥库口令: 用户证书密码 hU6HgL78Bw6x
再次输入新口令: 用户证书密码 hU6HgL78Bw6x
输入源密钥库口令: 用户证书密码 hU6HgL78Bw6x
已成功导入别名 my-user 的条目。
已完成导入命令: 1 个条目成功导入, 0 个条目失败或取消

# 创建生产者和消费者客户端连接配置文件，注意用户密码，CA 证书密码
$ cat << EOF > client-ssl.properties
security.protocol=SSL
ssl.truststore.location=/root/ssl/user-truststore.jks
ssl.truststore.password=V27UGXKJ1c2a
ssl.endpoint.identification.algorithm=

ssl.keystore.location=/root/ssl/user-keystore.jks
ssl.keystore.password=hU6HgL78Bw6x
ssl.key.password=hU6HgL78Bw6x
EOF

# 生产者
$ kafka-console-producer.sh --bootstrap-server 10.0.128.202:30762 --topic my-topic --producer.config ./client-ssl.properties
>hello1
>hello2
>hello3
>hello4
>

# 消费者
$ kafka-console-consumer.sh --bootstrap-server 10.0.128.202:30762 --topic my-topic --consumer.config ./client-ssl.properties --from-beginning --group my-group
hello1
hello2
hello3
hello4
```


# 组合七


```bash
# 处理根证书
$ openssl genrsa -out ca.key 2048

$ openssl req -x509 -sha256 -new -nodes -key ca.key -days 3650 -out ca.crt
You are about to be asked to enter information that will be incorporated
into your certificate request.
What you are about to enter is what is called a Distinguished Name or a DN.
There are quite a few fields but you can leave some blank
For some fields there will be a default value,
If you enter '.', the field will be left blank.
-----
Country Name (2 letter code) [AU]:CN  # 国家
State or Province Name (full name) [Some-State]:hubeisheng  # 省
Locality Name (eg, city) []:wuhanshi  # 市
Organization Name (eg, company) [Internet Widgits Pty Ltd]:trent  # 公司名称
Organizational Unit Name (eg, section) []:wuhan-trent  # 公司部门
Common Name (e.g. server FQDN or YOUR name) []:www.trent.com  # 域名
Email Address []:zhihu@trent.com  # 邮箱

$ openssl pkcs12 -export -in ca.crt -inkey ca.key -name custom-key -password pass:rhPunGUkFtaz3xNnFmVTuHMBrDHvdaRl -out ca.keystore.p12

# 处理服务的证书
$ openssl genrsa -out tls.key 2048

$ openssl req -new -key tls.key -out tls.csr
You are about to be asked to enter information that will be incorporated
into your certificate request.
What you are about to enter is what is called a Distinguished Name or a DN.
There are quite a few fields but you can leave some blank
For some fields there will be a default value,
If you enter '.', the field will be left blank.
-----
Country Name (2 letter code) [AU]:CN
State or Province Name (full name) [Some-State]:hubeisheng
Locality Name (eg, city) []:wuhanshi
Organization Name (eg, company) [Internet Widgits Pty Ltd]:alauda
Organizational Unit Name (eg, section) []:dataservice
Common Name (e.g. server FQDN or YOUR name) []:www.alauda.io
Email Address []:zhihu@alauda.io

Please enter the following 'extra' attributes
to be sent with your certificate request
A challenge password []:
An optional company name []:

$ cat > client.ext << EOF
authorityKeyIdentifier=keyid,issuer
basicConstraints=CA:FALSE
subjectAltName = @alt_names

[alt_names]
DNS.1 = 192.168.132.208
DNS.2 = 192.168.132.209
DNS.3 = 192.168.132.210
DNS.4 = 192.168.132.213
DNS.5 = my-cluster-kafka-0
DNS.6 = my-cluster-kafka-1
DNS.7 = my-cluster-kafka-2
DNS.8 = my-cluster-kafka-bootstrap
DNS.9 = my-cluster-kafka-brokers
DNS.10 = my-cluster-kafka-exporter
DNS.11 = my-cluster-kafka-external-bootstrap
EOF

$ openssl x509 -req -in tls.csr -CA ca.crt -CAkey ca.key -CAcreateserial -out tls.crt -days 3650 -sha256 -extfile client.ext

$ openssl pkcs12 -export -in tls.crt -inkey tls.key -name custom-key -password pass:rhPunGUkFtaz3xNnFmVTuHMBrDHvdaRl -out tls.keystore.p12

$ ll
total 40
drwx------ 1 root root  134 Aug 15 15:11 ./
drwxr-xr-x 1 root root   62 Aug 15 13:09 ../
-rw-r--r-- 1 root root 1460 Aug 15 15:03 ca.crt
-rw------- 1 root root 1679 Aug 15 15:01 ca.key
-rw------- 1 root root 2714 Aug 15 15:06 ca.keystore.p12
-rw-r--r-- 1 root root   41 Aug 15 15:11 ca.srl
-rw-r--r-- 1 root root  428 Aug 15 15:10 client.ext
-rw-r--r-- 1 root root 1769 Aug 15 15:11 tls.crt
-rw-r--r-- 1 root root 1066 Aug 15 15:08 tls.csr
-rw------- 1 root root 1679 Aug 15 15:07 tls.key

$ kubectl -n hz-kafka create secret generic my-cluster-lets-encrypt --from-file=ca.crt=ca.crt --from-file=tls.crt=tls.crt --from-file=tls.key=tls.key

```

```yaml

apiVersion: cert-manager.io/v1
kind: Certificate
metadata:
  name: my-cluster-lets-encrypt
  namespace: hz-kafka
spec:
  secretName: my-cluster-lets-encrypt
  issuerRef:
    name: cpaas-ca
    kind: ClusterIssuer
    group: cert-manager.io
  subject:
    organizations:
      - my-org
  dnsNames:
    - 192.168.132.208
    - 192.168.132.209
    - 192.168.132.210
    - 192.168.132.213
    - my-cluster-kafka-0
    - my-cluster-kafka-1
    - my-cluster-kafka-2
    - my-cluster-kafka-bootstrap
    - my-cluster-kafka-brokers
    - my-cluster-kafka-exporter
    - my-cluster-kafka-external-bootstrap

---


apiVersion: kafka.strimzi.io/v1beta1
kind: Kafka
metadata:
  name: my-cluster
  namespace: hz-kafka
spec:
  clusterCa:
    validityDays: 3650
  entityOperator:
    tlsSidecar:
      resources:
        limits:
          cpu: 200m
          memory: 128Mi
        requests:
          cpu: 200m
          memory: 128Mi
    topicOperator:
      jvmOptions:
        -Xms: 500m
        -Xmx: 500m
      resources:
        limits:
          cpu: 1
          memory: 2Gi
        requests:
          cpu: 1
          memory: 2Gi
    userOperator:
      jvmOptions:
        -Xms: 500m
        -Xmx: 500m
      resources:
        limits:
          cpu: 1
          memory: 2Gi
        requests:
          cpu: 1
          memory: 2Gi
  kafka:
    logging:
      type: inline
      loggers:
        kafka.root.logger.level: "TRACE"
    tlsSidecar:
      resources:
        limits:
          cpu: 200m
          memory: 128Mi
        requests:
          cpu: 200m
          memory: 128Mi
    config:
      log.message.format.version: "2.5"
      offsets.topic.replication.factor: "3"
      transaction.state.log.min.isr: "2"
      transaction.state.log.replication.factor: "3"
    resources:
      limits:
        cpu: 2
        memory: 4Gi
      requests:
        cpu: 2
        memory: 4Gi
    version: 2.5.0
    template:
      pod:
        affinity:
          podAntiAffinity:
            requiredDuringSchedulingIgnoredDuringExecution:
              - labelSelector:
                  matchLabels:
                    app.kubernetes.io/name: kafka
                    strimzi.io/cluster: my-cluster
                    strimzi.io/kind: Kafka
                    strimzi.io/name: my-cluster-kafka
                topologyKey: kubernetes.io/hostname
        securityContext:
          fsGroup: 0
          runAsUser: 0
    storage:
      type: ephemeral
    replicas: 3
    jvmOptions:
      -Xms: 1g
      -Xmx: 1g
    listeners:
      plain:
        authentication:
          type: scram-sha-512
      tls:
        authentication:
          type: tls
        configuration:
          brokerCertChainAndKey:
            secretName: my-cluster-lets-encrypt
            certificate: tls.crt
            key: tls.key
      external:
        type: nodeport
        tls: true
        authentication:
          type: tls
        configuration:
          brokerCertChainAndKey:
            secretName: my-cluster-lets-encrypt
            certificate: tls.crt
            key: tls.key
    authorization:
      type: simple
  kafkaExporter:
    groupRegex: .*
    resources:
      limits:
        cpu: 1
        memory: 1Gi
      requests:
        cpu: 1
        memory: 1Gi
    topicRegex: .*
  zookeeper:
    logging:
      type: inline
      loggers:
        zookeeper.root.logger: "TRACE"
    jvmOptions:
      -Xms: 1g
      -Xmx: 1g
      javaSystemProperties:
        - name: zookeeper.ssl.hostnameVerification
          value: "false"
        - name: zookeeper.ssl.quorum.hostnameVerification
          value: "false"
    replicas: 3
    resources:
      limits:
        cpu: 2
        memory: 4Gi
      requests:
        cpu: 2
        memory: 4Gi
    storage:
      type: ephemeral
    template:
      pod:
        affinity:
          podAntiAffinity:
            requiredDuringSchedulingIgnoredDuringExecution:
              - labelSelector:
                  matchLabels:
                    app.kubernetes.io/name: zookeeper
                    strimzi.io/cluster: my-cluster
                    strimzi.io/kind: Kafka
                    strimzi.io/name: my-cluster-zookeeper
                topologyKey: kubernetes.io/hostname
        securityContext:
          fsGroup: 0
          runAsUser: 0


---

# 创建 KafkaUser 集群的 yaml 文件
apiVersion: kafka.strimzi.io/v1beta1
kind: KafkaUser
metadata:
  name: my-user
  labels:
    strimzi.io/cluster: my-cluster
  namespace: hz-kafka
spec:
  authentication:
    type: tls
  authorization:
    type: simple
    acls:
      - resource:
          type: topic
          name: my-topic
          patternType: literal
        operation: Read
        host: '*'
      - resource:
          type: topic
          name: my-topic
          patternType: literal
        operation: Describe
        host: '*'
      - resource:
          type: group
          name: my-group
          patternType: literal
        operation: Read
        host: '*'
      - resource:
          type: topic
          name: my-topic
          patternType: literal
        operation: Write
        host: '*'
      - resource:
          type: topic
          name: my-topic
          patternType: literal
        operation: Create
        host: '*'
      - resource:
          type: topic
          name: my-topic
          patternType: literal
        operation: Describe
        host: '*'

---

# 创建 KafkaTopic 集群的 yaml 文件
apiVersion: kafka.strimzi.io/v1beta1
kind: KafkaTopic
metadata:
  name: my-topic
  labels:
    strimzi.io/cluster: my-cluster
  namespace: hz-kafka
spec:
  partitions: 3
  replicas: 3
  config:
    retention.ms: 604800000
    segment.bytes: 1073741824



root@my-cluster-kafka-0:/opt/kafka# cat /tmp/strimzi.properties
##############################
##############################
# This file is automatically generated by the Strimzi Cluster Operator
# Any changes to this file will be ignored and overwritten!
##############################
##############################

##########
# Broker ID
##########
broker.id=0

##########
# Zookeeper
##########
zookeeper.connect=localhost:2181

##########
# Kafka message logs configuration
##########
log.dirs=/var/lib/kafka/data/kafka-log0

##########
# Replication listener
##########
# cluster-ca-certs                         ->  /tmp/kafka/cluster.truststore.p12
# broker-certs                             ->  /tmp/kafka/cluster.keystore.p12
# certificates/custom-tls-9093-certs       ->  /tmp/kafka/custom-tls-9093.keystore.p12
# certificates/custom-external-9094-certs  ->  /tmp/kafka/custom-external-9094.keystore.p12
# client-ca-certs                          ->  /tmp/kafka/clients.truststore.p12
# certificates/oauth-plain-9092-certs      ->  /tmp/kafka/oauth-plain-9092.truststore.p12
# certificates/oauth-tls-9093-certs        ->  /tmp/kafka/oauth-tls-9093.truststore.p12
# certificates/oauth-external-9094-certs   ->  /tmp/kafka/oauth-external-9094.truststore.p12
# certificates/authz-keycloak-certs        ->  /tmp/kafka/authz-keycloak.truststore.p12

listener.name.replication-9091.ssl.keystore.location=/tmp/kafka/cluster.keystore.p12
listener.name.replication-9091.ssl.keystore.password=Glzn37IrEz-gMRCClsp3NWjOp3kmL_nz
listener.name.replication-9091.ssl.keystore.type=PKCS12
listener.name.replication-9091.ssl.truststore.location=/tmp/kafka/cluster.truststore.p12
listener.name.replication-9091.ssl.truststore.password=Glzn37IrEz-gMRCClsp3NWjOp3kmL_nz
listener.name.replication-9091.ssl.truststore.type=PKCS12
listener.name.replication-9091.ssl.client.auth=required

##########
# Plain listener
##########
listener.name.plain-9092.scram-sha-512.sasl.jaas.config=org.apache.kafka.common.security.scram.ScramLoginModule required;
listener.name.plain-9092.sasl.enabled.mechanisms=SCRAM-SHA-512


##########
# TLS listener
##########
listener.name.tls-9093.ssl.client.auth=required
listener.name.tls-9093.ssl.truststore.location=/tmp/kafka/clients.truststore.p12
listener.name.tls-9093.ssl.truststore.password=Glzn37IrEz-gMRCClsp3NWjOp3kmL_nz
listener.name.tls-9093.ssl.truststore.type=PKCS12

listener.name.tls-9093.ssl.keystore.location=/tmp/kafka/custom-tls-9093.keystore.p12
listener.name.tls-9093.ssl.keystore.password=Glzn37IrEz-gMRCClsp3NWjOp3kmL_nz
listener.name.tls-9093.ssl.keystore.type=PKCS12

##########
# External listener
##########
listener.name.external-9094.ssl.client.auth=required
listener.name.external-9094.ssl.truststore.location=/tmp/kafka/clients.truststore.p12
listener.name.external-9094.ssl.truststore.password=Glzn37IrEz-gMRCClsp3NWjOp3kmL_nz
listener.name.external-9094.ssl.truststore.type=PKCS12

listener.name.external-9094.ssl.keystore.location=/tmp/kafka/custom-external-9094.keystore.p12
listener.name.external-9094.ssl.keystore.password=Glzn37IrEz-gMRCClsp3NWjOp3kmL_nz
listener.name.external-9094.ssl.keystore.type=PKCS12

##########
# Common listener configuration
##########
listeners=REPLICATION-9091://0.0.0.0:9091,PLAIN-9092://0.0.0.0:9092,TLS-9093://0.0.0.0:9093,EXTERNAL-9094://0.0.0.0:9094
advertised.listeners=REPLICATION-9091://my-cluster-kafka-0.my-cluster-kafka-brokers.hz-kafka.svc:9091,PLAIN-9092://my-cluster-kafka-0.my-cluster-kafka-brokers.hz-kafka.svc:9092,TLS-9093://my-cluster-kafka-0.my-cluster-kafka-brokers.hz-kafka.svc:9093,EXTERNAL-9094://192.168.132.208:31023
listener.security.protocol.map=REPLICATION-9091:SSL,PLAIN-9092:SASL_PLAINTEXT,TLS-9093:SSL,EXTERNAL-9094:SSL
inter.broker.listener.name=REPLICATION-9091
sasl.enabled.mechanisms=
ssl.secure.random.implementation=SHA1PRNG
ssl.endpoint.identification.algorithm=HTTPS

##########
# Authorization
##########
authorizer.class.name=kafka.security.auth.SimpleAclAuthorizer
super.users=User:CN=my-cluster-kafka,O=io.strimzi;User:CN=my-cluster-entity-operator,O=io.strimzi;User:CN=my-cluster-kafka-exporter,O=io.strimzi;User:CN=my-cluster-cruise-control,O=io.strimzi;User:CN=cluster-operator,O=io.strimzi

##########
# User provided configuration
##########
log.message.format.version=2.5
offsets.topic.replication.factor=3
transaction.state.log.min.isr=2
transaction.state.log.replication.factor=3

```


验证结果：

```bash

# openssl pkcs12 -export -in tls.crt -inkey tls.key -name custom-key -password pass:rhPunGUkFtaz3xNnFmVTuHMBrDHvdaRl -out custom-tls-9093.keystore.p12


# 获取 CA 证书
$ kubectl -n hz-kafka get secret my-cluster-lets-encrypt -o jsonpath='{.data.ca\.crt}' | base64 -d > ca.crt

# 将 CA 证书导入 user-truststore.jks 文件中
$ keytool -keystore user-truststore.jks -alias CARoot -import -file ca.crt
Enter keystore password: V27UGXKJ1c2a
Re-enter new password: V27UGXKJ1c2a

# 获取用户证书
$ kubectl -n hz-kafka get secret my-user -o jsonpath='{.data.user\.p12}' | base64 -d > user.p12

# 获取用户证书密码
$ kubectl -n hz-kafka get secret my-user -o jsonpath='{.data.user\.password}' | base64 -d
gDn1a3rwm3Cl

# 将用户证书导入 user-keystore.jks 文件中
$ keytool -importkeystore -srckeystore user.p12 -destkeystore user-keystore.jks -deststoretype pkcs12
正在将密钥库 user.p12 导入到 user-keystore.jks...
输入目标密钥库口令: 用户证书密码 gDn1a3rwm3Cl
再次输入新口令: 用户证书密码 gDn1a3rwm3Cl
输入源密钥库口令: 用户证书密码 gDn1a3rwm3Cl
已成功导入别名 my-user 的条目。
已完成导入命令: 1 个条目成功导入, 0 个条目失败或取消

# 创建生产者和消费者客户端连接配置文件，注意用户密码，CA 证书密码
$ cat << EOF > client-ssl.properties
security.protocol=SSL
ssl.truststore.location=/root/kafka-secret/user-truststore.jks
ssl.truststore.password=V27UGXKJ1c2a
ssl.endpoint.identification.algorithm=

ssl.keystore.location=/root/kafka-secret/user-keystore.jks
ssl.keystore.password=gDn1a3rwm3Cl
ssl.key.password=gDn1a3rwm3Cl
EOF

$ kafka-topics.sh --bootstrap-server 192.168.132.213:31831 --command-config ./client-ssl.properties --list

# 生产者
$ kafka-console-producer.sh --bootstrap-server 192.168.132.213:31831 --topic my-topic --producer.config ./client-ssl.properties
>hello1
>hello2
>hello3
>hello4
>hello5
>^C

# 消费者
$ kafka-console-consumer.sh --bootstrap-server 192.168.132.213:31831 --topic my-topic --consumer.config ./client-ssl.properties --from-beginning --group my-group
hello1
hello2
hello3
hello4


#######################################################################################################

# 创建 pod 作为生产者和消费者客户端
$ kubectl -n hz-kafka run kafka-test -ti --image=192.168.134.214:11443/middleware/kafka/release/0.18.0/kafka-2-5-0:fix-ipv6.2207242344 --rm=true --restart=Never bash

$ cat << EOF > client-ssl.properties
security.protocol=SSL
ssl.truststore.location=/home/kafka/user-truststore.jks
ssl.truststore.password=V27UGXKJ1c2a
ssl.endpoint.identification.algorithm=

ssl.keystore.location=/home/kafka/user-keystore.jks
ssl.keystore.password=gDn1a3rwm3Cl
ssl.key.password=gDn1a3rwm3Cl
EOF

kubectl -n hz-kafka cp client-ssl.properties kafka-test:/home/kafka/
kubectl -n hz-kafka cp user-truststore.jks kafka-test:/home/kafka/
kubectl -n hz-kafka cp user-keystore.jks kafka-test:/home/kafka/


$ /opt/kafka/bin/kafka-topics.sh --bootstrap-server my-cluster-kafka-bootstrap:9093 --command-config ./client-ssl.properties --list

# 生产者
$ /opt/kafka/bin/kafka-console-producer.sh --bootstrap-server my-cluster-kafka-bootstrap:9093 --topic my-topic --producer.config ./client-ssl.properties


# 消费者
$ /opt/kafka/bin/kafka-console-consumer.sh --bootstrap-server my-cluster-kafka-bootstrap:9093 --topic my-topic --consumer.config ./client-ssl.properties --from-beginning --group my-group


```



